name: Auto Release with Smart Version Retention

on:
  push:
    branches:
      - master

jobs:
  auto-release:
    if: contains(github.event.head_commit.message, 'RELEASE')
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install dependencies
        run: |
          sudo apt update -y
          sudo apt install -y gh python3-pip
          pip install packaging

      - name: Authenticate GitHub CLI
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: gh auth setup-git

      - name: Auto-filter, release, and clean
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          python3 <<'PYCODE'
import subprocess
from pathlib import Path
from packaging.version import Version
from collections import defaultdict

# --- Collect release archives ---
releases_dir = Path("releases")
all_zips = list(releases_dir.glob("root_cyberwarfare-*.zip"))
version_map = defaultdict(list)

for zip_file in all_zips:
    try:
        version_str = zip_file.stem.split("root_cyberwarfare-")[1]
        Version(version_str)
        version_map[version_str].append(zip_file)
    except Exception:
        continue

if not version_map:
    print("No valid release archives found.")
    exit(0)

# --- Build version groups ---
def get_keys(version):
    v = Version(version)
    return {
        "major": f"{v.major}",
        "minor": f"{v.major}.{v.minor}",
        "patch": f"{v.major}.{v.minor}.{v.micro}"
    }

major_map, minor_map, patch_map = defaultdict(list), defaultdict(list), defaultdict(list)

for v_str in version_map:
    keys = get_keys(v_str)
    major_map[keys["major"]].append(v_str)
    minor_map[keys["minor"]].append(v_str)
    patch_map[keys["patch"]].append(v_str)

# --- Keep 1 major / 2 minor / 3 patch versions ---
kept_versions = set()
latest_major = sorted(major_map.keys(), key=Version, reverse=True)[:1]
for major in latest_major:
    minors = sorted(set(f"{major}.{v.split('.')[1]}" for v in major_map[major]), key=Version, reverse=True)[:2]
    for minor in minors:
        patches = sorted(set(f"{minor}.{v.split('.')[2]}" for v in minor_map[minor]), key=Version, reverse=True)[:3]
        for patch in patches:
            builds = sorted([v for v in patch_map[patch]], key=Version, reverse=True)
            if builds:
                kept_versions.add(builds[0])

print("Keeping versions:", kept_versions)

# --- Delete old archives ---
for zip_file in all_zips:
    version_str = zip_file.stem.split("root_cyberwarfare-")[1]
    if version_str not in kept_versions:
        print(f"Deleting old archive: {zip_file}")
        zip_file.unlink()

# --- Commit deletions (if any) ---
subprocess.run(["git", "config", "user.name", "github-actions"], check=True)
subprocess.run(["git", "config", "user.email", "github-actions@github.com"], check=True)
subprocess.run(["git", "add", "releases"], check=True)
subprocess.run(["git", "commit", "-m", "Cleanup: remove old mod archives"], check=False)
subprocess.run(["git", "push"], check=False)

# --- Process releases ---
latest_version = None
latest_version_obj = None

for version in sorted(kept_versions, key=Version):
    files = version_map[version]
    tag_exists = subprocess.run(["git", "tag", "--list", version], stdout=subprocess.PIPE).stdout.decode().strip()

    if not tag_exists:
        subprocess.run(["git", "tag", version], check=True)
        subprocess.run(["git", "push", "origin", version], check=True)
    else:
        print(f"Tag {version} already exists, updating release.")

    # Extract changelog section
    changelog_path = Path("releases/CHANGELOG.md")
    if changelog_path.exists():
        with open(changelog_path) as f:
            lines = f.readlines()
        section, in_section = [], False
        for line in lines:
            if line.startswith("## "):
                if in_section:
                    break
                in_section = True
            if in_section:
                section.append(line.rstrip())
        notes = "\n".join(section)
    else:
        notes = f"Automated release for version {version}."

    # Check if release exists
    release_exists = subprocess.run(
        ["gh", "release", "view", version],
        stdout=subprocess.DEVNULL,
        stderr=subprocess.DEVNULL
    ).returncode == 0

    if release_exists:
        print(f"Updating existing release {version}")
        assets = subprocess.run(
            ["gh", "release", "view", version, "--json", "assets", "--jq", ".assets[].name"],
            stdout=subprocess.PIPE
        ).stdout.decode().strip().splitlines()
        for asset in assets:
            if asset:
                subprocess.run(["gh", "release", "delete-asset", version, asset, "--yes"], check=True)

        for f in files:
            subprocess.run(["gh", "release", "upload", version, str(f), "--clobber"], check=True)
        subprocess.run(["gh", "release", "edit", version, "--notes", notes], check=True)
    else:
        print(f"Creating new release {version}")
        subprocess.run([
            "gh", "release", "create", version,
            *[str(f) for f in files],
            "--title", f"root_cyberwarfare {version}",
            "--notes", notes
        ], check=True)

    v_obj = Version(version)
    if not latest_version_obj or v_obj > latest_version_obj:
        latest_version = version
        latest_version_obj = v_obj

# --- Attach latest.zip if exists ---
latest_zip = releases_dir / "root_cyberwarfare-latest.zip"
if latest_version and latest_zip.exists():
    subprocess.run([
        "gh", "release", "upload", latest_version, str(latest_zip), "--clobber"
    ], check=True)
    print(f"Attached latest.zip to {latest_version}")
PYCODE
